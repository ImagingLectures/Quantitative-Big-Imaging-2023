{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baking-aggregate",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Uncertainty, Statistics, and Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-engineering",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Uncertainty, Statistics, and Reproducibility</h1>\n",
    "\n",
    "<p>\n",
    "<b>Quantitative Big Imaging - ETHZ: 227-0966-00L</b>\n",
    "<br />\n",
    "</p>\n",
    "<br />\n",
    "<p style=\"font-size:1em;\">April 14, 2022</p>\n",
    "<br /><br />\n",
    "<p style=\"font-size:1.5em;padding-bottom: 0.25em;\">Anders Kaestner</p>  \n",
    "<p style=\"font-size:1em;\">Laboratory for Neutron Scattering and Imaging<br />Paul Scherrer Institut</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-recommendation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:19:50.015031Z",
     "start_time": "2023-04-16T11:19:49.828656Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import skimage.filters as flt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import tifffile as tiff\n",
    "from lecture8_support import *\n",
    "import confmap as cm\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "#plt.style.use('ggplot')\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "dcolors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc76ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Literature / Useful References\n",
    "\n",
    "### Books\n",
    "- Jean Claude, [_Morphometry with R_](http://link.springer.com/book/10.1007%2F978-0-387-77789-4), __Chapter 3__ \n",
    "- John C. Russ, [_The Image Processing Handbook_](http://dx.doi.org/10.1201/9780203881095),(Boca Raton, CRC Press)\n",
    "- Gregory J. Privitera, _Statistics for the Behavioral Sciences_ [__Chapter 8__](http://www.sagepub.com/upm-data/40007_Chapter8.pdf)\n",
    "- Drosg, 2009, [\"Dealing with uncertainties\"](https://doi.org/0.1007/978-3-642-01384-3), Springer Verlag  \n",
    "- M. Grabe, 2014,[\"Measurement Uncertainties in Science and Technology\"](https://doi.org/10.1007/978-3-319-04888-8), Springer Verlag  \n",
    "- Ch. Gillmann, 2018,[\"Image processing under uncertainty\"](https://kluedo.ub.rptu.de/frontdoor/deliver/index/docId/5470/file/Dissertation_Christina_Gillmann.pdf), PhD Thesis, Uni Kaiserslautern\n",
    "- Leland and Wilkinson, [_Grammar of Graphics_](http://www.springer.com/gp/book/9780387245447)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-chemical",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Papers / Sites\n",
    "- [Databases Introduction](http://swcarpentry.github.io/sql-novice-survey/)\n",
    "- [Measurement errors - European Commission Glossary](https://cros-legacy.ec.europa.eu/content/measurement-error_en)\n",
    "- [Detection limit - Wikipedia](https://en.wikipedia.org/wiki/Detection_limit)  \n",
    "- [Error propagation](https://www.webassign.net/question_assets/unccolphysmechl1/measurements/manual.html)  \n",
    "- [Error bands - Stack exchange](https://physics.stackexchange.com/questions/496841/what-should-be-the-real-error-band-of-a-fit-function)\n",
    "- [Visualizing Genomic Data](http://circos.ca/documentation/course/visualizing-genomic-data.pdf) (General Visualization Techniques)\n",
    "- [NIMRod Parameter Studies](http://www.messagelab.monash.edu.au/nimrod)\n",
    "\n",
    "- M.E. Wolak, D.J. Fairbairn, Y.R. Paulsen (2012) Guidelines for Estimating Repeatability. Methods in Ecology and Evolution 3(1):129-137.\n",
    "- David J.C. MacKay, [Bayesian Interpolation](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.9072) (1991) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-dayton",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Videos / Podcasts\n",
    "- [Google/Stanford Statistics Intro](https://www.youtube.com/watch?v=YFC2KUmEebc)\n",
    "- Last Week Tonight with John Oliver: [Scientific Studies](https://www.youtube.com/watch?v=0Rnq1NpHdmw)\n",
    "- [Credibility Crisis](https://www.datacamp.com/community/podcast/credibility-crisis-in-data-science)\n",
    "\n",
    "### Further material\n",
    "#### Slides\n",
    "- [How to solve NLP problems](https://twitter.com/sleepinyourhat/status/1105946169165955073?s=20)\n",
    "- Kieran Healy, [Data Visualization - A practical introduction](https://socviz.co/lookatdata.html)\n",
    "- [P-Values with Puppies](https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0)\n",
    "\n",
    "#### Model Evaluation\n",
    "\n",
    "- [Julia Evans - Recalling with Precision](https://www.youtube.com/watch?v=ryZL4XNUmwo)\n",
    "- [Stripe's Next Top Model](https://github.com/stripe/topmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-drawing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Previously on QBI ...\n",
    "  \n",
    "<br> \n",
    "<img src=\"figures/08-all_icons-statistics.svg\" style=\"height:300px\" />\n",
    "\n",
    "\n",
    "- Image Enhancement \n",
    " - Highlighting the contrast of interest in images\n",
    " - Minimizing Noise\n",
    "- Understanding image histograms\n",
    "- Automatic Methods\n",
    "- Component Labeling\n",
    "- Single Shape Analysis\n",
    "- Complicated Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-colonial",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today's outline\n",
    "\n",
    "- Motivation (Why and How?)\n",
    "- Scientific Goals\n",
    "- Reproducibility\n",
    "- Predicting and Validating\n",
    "- Statistical metrics and results\n",
    "- Parameterization\n",
    "    - Parameter sweep\n",
    "    - Sensitivity analysis\n",
    "- Data frames\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-photographer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantitative \"Big\" Imaging\n",
    "\n",
    "\n",
    "The course has covered imaging enough and there have been a few quantitative metrics, \n",
    "\n",
    "...but \"big\" has not really mentioned!\n",
    "\n",
    "So, what does __big__ mean?\n",
    "\n",
    "- Not just / even large\n",
    "- it means being ready for _big data_\n",
    "    - The three V's: __V__ olume, __V__ elocity, __V__ ariety\n",
    "    - scalable, fast, easy to customize\n",
    "\n",
    "\n",
    "So what is \"big\" imaging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-conjunction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "Scientific Studies all try to get to a single or few numbers  \n",
    "- Make sure this number is describing the structure well (earlier lectures)\n",
    "- Making sure the number is meaningful (__today!__)  \n",
    " \n",
    "How do we:\n",
    "1. Compare the number from different samples and groups?  \n",
    "     - Within a sample or same type of samples\n",
    "     - Between samples\n",
    "3. Compare different processing steps like filter choice, minimum volume, resolution, etc?  \n",
    "4. Evaluate our parameter selection?  \n",
    "5. Ensure our techniques do what they are supposed to do?  \n",
    "6. Visualize so much data? Are there rules?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-advisory",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What do we start with?\n",
    "\n",
    "Going back to our original cell image\n",
    "\n",
    "1. We have been able to __get rid of the noise__ in the image and __find all the cells__ (lecture 2-4)  \n",
    "\n",
    "1. We have __analyzed the shape__ of the cells (lecture 5)  \n",
    "\n",
    "1. We even __separated cells joined together__ using Watershed (lecture 6)  \n",
    "\n",
    "1. We have created even more __metrics characterizing the distribution__ (lecture 7)\n",
    "\n",
    "We have at least a few samples (or different regions), \n",
    "- large number of metrics and \n",
    "- and almost as large number of parameters to _tune_\n",
    "\n",
    "__How do we do something meaningful with it?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-shield",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Correlation and Causation\n",
    "\n",
    "\n",
    "One of the most repeated criticisms of scientific work is that correlation and causation are confused. \n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column25\">\n",
    "        \n",
    "__Correlation__  \n",
    "    \n",
    "<center><img src=\"figures/np_scatterplot_206502_000000.svg\" style=\"height:150px\"/></center>\n",
    "    \n",
    " - means a statistical relationship\n",
    " - very easy to show (single calculation)\n",
    "        \n",
    "</div>\n",
    "<div class=\"column35\">\n",
    "         \n",
    "__Causation__  \n",
    "    \n",
    "<center><img src=\"figures/np_domino-effect_2020716_000000.svg\" style=\"height:150px\"/></center>      \n",
    "    \n",
    " - implies there is a mechanism between A and B\n",
    " - can be very difficult to show (impossible to prove)\n",
    "         \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-cloud",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observational or Controlled\n",
    "\n",
    "There are two broad classes of data and scientific studies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-palestine",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Observational \n",
    "- Controlled\n",
    "\n",
    "Each type appears, but it is more likely to perform observational studies in the early stages of a project to gain an overview of the working field. From this study it you will make observations for more detailed studies which then are controlled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-sheriff",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"row\">\n",
    "<div class=\"column\">\n",
    "<center>\n",
    "    \n",
    "__Observational__  \n",
    "    \n",
    "<img src=\"figures/np_museum-visit_68542_000000.svg\" style=\"height:400px\"/>\n",
    "</center>              \n",
    "</div>\n",
    "<div class=\"column\">\n",
    "<center>\n",
    "    \n",
    "__Controlled__  \n",
    "    \n",
    "<img src=\"figures/np_puppet_57357_000000.svg\" style=\"height:400px\"/>\n",
    "</center>      \n",
    "</div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-douglas",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/noun_MuseumVisit.pdf\n",
    "---\n",
    "scale: 50%\n",
    "name: fig_observer\n",
    "---\n",
    "In observational experiments you stand back and only observe what is happening.\n",
    "```\n",
    "\n",
    "```{figure} figures/noun_puppet.pdf\n",
    "---\n",
    "scale: 50%\n",
    "name: fig_controller\n",
    "---\n",
    "In controlled experiments you prepare the samples for a specific purpose and control the environment.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-affairs",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observational"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-tuning",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In observational experiments you are not interfering with the observed phenomenon. You only make a selection of specimens or individuals that will be measured as they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-miami",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"row\">\n",
    "<div class=\"column45\">    \n",
    "    \n",
    "__Exploring large datasets looking for trends__\n",
    " - Population is random\n",
    " - Not always hypothesis driven\n",
    " - Rarely leads to causation\n",
    "\n",
    "\n",
    "#### Examples of observational experiments\n",
    "- We examined 100 people \n",
    "    - the ones with blue eyes were on average 10cm taller\n",
    "    \n",
    "- In 100 cake samples\n",
    "    - we found a 0.9 correlation between baking time and bubble size\n",
    "    \n",
    "</div>\n",
    "<div class=\"column15\">\n",
    "<img src=\"figures/np_museum-visit_68542_000000.svg\" style=\"height:250px\"/>    \n",
    "</div>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-peace",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Controlled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-difficulty",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The controlled experiments are designed to explore specific aspects of a population or phenomenon. To achieve this, you want to introduce differences between different groups and keep one as reference. The reference group can be the unmodified samples or samples prepared with an wellknown process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-professional",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"row\">\n",
    "<div class=\"column45\">    \n",
    "    \n",
    "__Most scientific studies fall into this category__\n",
    " - Specifics of the groups are controlled\n",
    " - Can lead to causation\n",
    "\n",
    "#### Examples of controlled experiments\n",
    "- We examined 50 mice with gene XYZ off and 50 gene XYZ on and as the foot size increased by 10%\n",
    "- We increased the temperature and the number of pores in the metal increased by 10%\n",
    " \n",
    "</div>\n",
    "<div class=\"column15\">\n",
    "<img src=\"figures/np_puppet_57357_000000.svg\" style=\"height:250px\"/>    \n",
    "</div>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-sellers",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Qualitative vs Quantitative\n",
    "\n",
    "Given the complexity of the tree, we need to do some pruning\n",
    "\n",
    "## Qualitative Assessment\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\">\n",
    "\n",
    "- Evaluating metrics using visual feedback\n",
    "- Compare with expectations from  \n",
    "    - other independent techniques \n",
    "    - or approach\n",
    "- Are there artifacts which are included in the output?\n",
    "- Do the shapes look correct?\n",
    "- Are they distributed as expected?\n",
    "- Is their orientation meaningful?\n",
    "\n",
    "</div>\n",
    "<div class=\"column\">\n",
    "        \n",
    "<img src=\"figures/poros.png\" style=\"width:800px\" />\n",
    "        \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-sociology",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantitative Metrics\n",
    "\n",
    "\n",
    "With a quantitative approach, we can calculate \n",
    "- the specific shape \n",
    "- or distribution metrics on the sample \n",
    "\n",
    "with each parameter and establish the relationship between \n",
    "- parameter \n",
    "- and metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e312d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Handling uncertainties in image processing\n",
    "\n",
    "## Why do we need to talk about the uncertain?\n",
    "> “Scientific knowledge is a body of statements of varying degree of certainty  \n",
    "> – some most unsure, some nearly sure, but none absolutely certain.”  \n",
    ">As found in Feynman, RP (1997) Surely You Are Joking, Mr. Feynman, Norton, New York."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0732b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:01:26.604371Z",
     "start_time": "2023-04-16T10:01:26.551283Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which uncertainties are we dealing with?\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column\">\n",
    "\n",
    "### Technical uncertainties\n",
    "- Metric\n",
    "- Noise\n",
    "- Unsharpness\n",
    "- Effects from image processing\n",
    "- Numerical errors \n",
    "    \n",
    "</div>\n",
    "<div class=\"column\">    \n",
    "\n",
    "### Field specific uncertainties\n",
    "- Model simplifications\n",
    "- Variations in population\n",
    "\n",
    "</div>\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d4aab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uncertainty categories\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column\">\n",
    "\n",
    "### Systematic\n",
    "Reproducible - no statistical analysis\n",
    "- Rounding errors \n",
    "- Uncalibrated systems\n",
    "- Algorithmic choices\n",
    "- Etc.\n",
    "\n",
    "</div>    \n",
    "<div class=\"column\">  \n",
    "    \n",
    "### Random\n",
    "Statistical fluctuations\n",
    "- Natural variations in studied population\n",
    "- Source fluctuations\n",
    "- Detector noise\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca27eb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Target practicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af46c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:33.102846Z",
     "start_time": "2023-04-16T11:13:32.778847Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "precacc(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0e65a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Target practicing in statistical terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6a621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:34.182549Z",
     "start_time": "2023-04-16T11:13:33.869345Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "precacc(1000,['Large bias','Small bias','Large variance','Small variance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b53e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Counting or measuring\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column\">\n",
    "        \n",
    "__Counting__  \n",
    "    \n",
    "<center><img src=\"figures/np_counting.png\" style=\"height:150px\"/></center>\n",
    "    \n",
    "    \n",
    " - Discrete countable items\n",
    " - Absolute values\n",
    "    \n",
    " Uncertainties: from preparation  \n",
    "\n",
    " _Example:_ area of segmented region\n",
    "        \n",
    "</div>\n",
    "<div class=\"column\">\n",
    "         \n",
    "__Measuring__  \n",
    "    \n",
    "<center><img src=\"figures/np_measure.png\" style=\"height:150px\"/></center>      \n",
    "    \n",
    " - Physical quantities\n",
    " - Values with uncertainties\n",
    "   \n",
    " Uncertainties: Noise, instrumentation  \n",
    "    \n",
    " _Example:_ mixing ratios from gray levels\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c97aec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Absolute vs relative uncertainties\n",
    "Errors must be compared from a neutral perspective\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\">\n",
    "\n",
    "### Absolute uncertainty\n",
    "Assume we can measure a distance with an error of 1mm\n",
    "> Distance to the moon - 384400km\n",
    "\n",
    "> The diameter of a coin - 20mm\n",
    "\n",
    "</div>        \n",
    "<div class=\"column\">        \n",
    "        \n",
    "### Relative uncertainty\n",
    "Relates the error to the measured quantity\n",
    "    \n",
    "> Distance to the moon - 0.000000002601457\n",
    "\n",
    "> Diameter of a coin - 0.05\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c881b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:06:03.929653Z",
     "start_time": "2023-04-16T10:06:03.875739Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Propagation of uncertainty\n",
    "\n",
    "\n",
    "<div class=\"row\">\n",
    "    <div class=\"column\">\n",
    "\n",
    "### Uncertainty of f(x)\n",
    "\n",
    "$$\\sigma_f(x) = \\frac{\\partial f}{\\partial x}\\cdot \\sigma_{x}$$        \n",
    "        \n",
    "</div>        \n",
    "<div class=\"column\">        \n",
    "        \n",
    "### Uncertainty of f(x,y)\n",
    "\n",
    "$$\\sigma_f(x,y) = \\left(\\frac{\\partial f}{\\partial x}\\cdot \\sigma_{x}\\right)^2 + \\left(\\frac{\\partial f}{\\partial y}\\cdot \\sigma_{y}\\right)^2 + \\underbrace{\\frac{\\partial f}{\\partial x}\\cdot\\frac{\\partial f}{\\partial y}\\cdot\\overline{\\sigma_{xy}}}_{\\mbox{x and y uncorrelated?}}$$        \n",
    "\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73011c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:09:31.558375Z",
     "start_time": "2023-04-16T10:09:31.502121Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uncertain quantities in imaging experiments\n",
    "\n",
    "- Pixel size\n",
    "- Segmentation\n",
    "- Sampling time stamps in time series\n",
    "- Intensity levels\n",
    "\n",
    "### Three examples\n",
    "- Determine the pixel size\n",
    "- Measure the perimeter length\n",
    "- Meassure water volume behind a pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396dac7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example measure the pixel size\n",
    "To measure pixel size we need:\n",
    "- An object with known length\n",
    "- An image of the object\n",
    "\n",
    "$$\\mbox{pixel size}=\\frac{\\mbox{Object length}}{\\mbox{Pixel distance between edges}}$$\n",
    "\n",
    "#### Uncertainty equation\n",
    "We assume that the two measured values are uncorrelated\n",
    "$$\\frac{\\sigma_{a/b}}{a/b}=\\sqrt{\\left(\\frac{\\sigma_a}{a}\\right)^2 + \\left(\\frac{\\sigma_b}{b}\\right)^2}$$\n",
    "\n",
    "[From this tutorial](https://www.webassign.net/question_assets/unccolphysmechl1/measurements/manual.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78e223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:11:07.277823Z",
     "start_time": "2023-04-16T10:11:07.228996Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Our measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07b3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:38.353357Z",
     "start_time": "2023-04-16T11:13:37.382229Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "img1 = tiff.imread('data/edge20mm_0000.tif')\n",
    "pic = plt.imread('figures/edge_object.jpg')\n",
    "fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "ax[0].imshow(pic)\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[0].set_title('Real object')\n",
    "\n",
    "ax[1].imshow(img1,vmin=300,vmax=30000,cmap='gray');\n",
    "ax[1].set_xlabel('x [pixels]')\n",
    "ax[1].set_ylabel('y [pixels]');\n",
    "arrow = patches.FancyArrowPatch((55,104), (526, 73),\n",
    "                                 mutation_scale=20,\n",
    "                                 #ec='blue',fc='cornflowerblue',\n",
    "                                 color='red',\n",
    "                                 arrowstyle='<|-|>',linewidth=3\n",
    "                                )\n",
    "ax[1].add_patch(arrow);\n",
    "#ax.annotate(text='', xy=(54,104), xytext=(527,71), arrowprops=dict(arrowstyle='<->',color='yellow',lw=4))\n",
    "d=np.sqrt((528-53)**2+(104-73)**2)\n",
    "ax[1].set_title('Distance between edges');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b65e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:11:28.367247Z",
     "start_time": "2023-04-16T10:11:28.315329Z"
    }
   },
   "source": [
    "| Quantity  | Measurement | Uncertainty   | Unit |\n",
    "|:---|---:|---:|---|\n",
    "| Caliper distance  | 20.0 | 0.05 | mm |\n",
    "| Pixel distance    | 464.9  | 0.32  | pixels |\n",
    "\n",
    "\n",
    "[A tutorial showing the detailed analysis](https://colab.research.google.com/github/ImagingELearning/resolution/blob/main/tutorials/02_PixelSize/02_PixelSize.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52c005",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Pixel size with uncertainty\n",
    "We know uncertainty equation for $a/b$. \n",
    "\n",
    "Let's plug in the pixel meassurements:\n",
    "\n",
    "$$\\frac{\\sigma_{Pixelsize}}{Pixelsize}=\\sqrt{\\biggl({\\frac{\\sigma_{pixels}}{pixels} }\\biggr)^2+ \\biggl({\\frac{\\sigma_{length}}{length}}\\biggr)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c60b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:40.134680Z",
     "start_time": "2023-04-16T11:13:40.084158Z"
    }
   },
   "outputs": [],
   "source": [
    "length       = 20.0 # mm\n",
    "error_length = 0.05 # mm\n",
    "pixels       = 464.9 # pixels\n",
    "error_pixels = 0.32  # pixels\n",
    "\n",
    "pixel_size = length/pixels\n",
    "\n",
    "rel_uncertainty = np.sqrt((error_pixels/pixels)**2 + (error_length/length)**2)\n",
    "\n",
    "print('Pixel size = {0:0.3f} mm/pixel +/- {1:0.4f}%'.format(pixel_size,rel_uncertainty*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1df8e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measurements in segmented images\n",
    "\n",
    "In lecture 5 we learned to measure\n",
    "\n",
    "- Area \n",
    "- Perimeter \n",
    "- Positions \n",
    "- Distances\n",
    "\n",
    "Considering them to be absolute values as we mostly just count pixels...\n",
    "\n",
    "_Let's see how the uncertainty of the pixel size among others changes this_ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb25e18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:13:28.597369Z",
     "start_time": "2023-04-16T10:13:28.538162Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Meassure the perimeter length\n",
    "\n",
    "The perimeter length has three sources of uncertainty:\n",
    "- How were the edge pixels identified?\n",
    "    _Method choices can introduce biases_\n",
    "- The pixel size... \n",
    "\n",
    "and...\n",
    "\n",
    "- How well was the image segmented?  \n",
    "    _Edges are segmented with least confidence_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301bf2b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selecting edge pixels\n",
    "\n",
    "A method to identify edge pixels is \n",
    "$$edge(f) = f - \\varepsilon_{SE}(f)$$\n",
    "which pixels depends on the used SE.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/edge_detail.png\" style=\"width:250px\"/>\n",
    "</center>\n",
    "\n",
    "#### Counting perimeter elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91483549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:41.930124Z",
     "start_time": "2023-04-16T11:13:41.608454Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "imgs=[plt.imread('figures/edge_detail_pixel_count.png'), \n",
    "      plt.imread('figures/edge_detail_outline.png'), \n",
    "      plt.imread('figures/edge_detail_centerline.png')]\n",
    "lbls=['Counting pixels (18)', 'Edges facing background (24)','Center line (20.5)']\n",
    "\n",
    "_,axs = plt.subplots(1,3, figsize=(15,6))\n",
    "for ax,img,lbl in zip(axs,imgs,lbls) :\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(lbl)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd8e9e",
   "metadata": {},
   "source": [
    "#### Perimeter length with uncertainty\n",
    "\n",
    "Let's assume we can trust the segmentation:\n",
    "- Edge is 18 pixels long\n",
    "- The pixel size is 0.043 mm/pixel $\\pm$  0.2593%\n",
    "\n",
    "##### Perimeter uncertainty equation\n",
    "In this case we sum the edge pixels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75eddd",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "_Derivation of the equation_\n",
    "\n",
    "The uncertainty of a sum of measurements $\\sum^N_{i=1}x_i$ each with all $x_i$ uncorrelated and the same uncertainty $\\sigma_x$. \n",
    "\n",
    "Lets start with the derivative:\n",
    "$\\frac{\\partial f}{\\partial x_i}=1\\quad \\forall i$\n",
    "\n",
    "now the uncertainty is the squared sum of all $x_i$  \n",
    "\n",
    "${\\sigma_{\\sum x_i}}^2 = \\sum_{i=1}^N {\\sigma_x}^2 = N {\\sigma_x}^2$\n",
    "\n",
    "which leads to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1e7e7",
   "metadata": {},
   "source": [
    "$$\\sigma_{\\sum x_i} = \\sigma_x \\cdot \\sqrt{N}$$\n",
    "\n",
    "We have $\\sigma_{Pixelsize}$=0.11 $\\mu{}m$, which gives $\\sigma_{Edgelength}=0.11\\cdot\\sqrt{18}=0.506 \\mu{}m$\n",
    "\n",
    "The edge length is 774 $\\pm$ 0.5 $\\mu{}m$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131a2ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measure water volume from gray levels\n",
    "In neutron imaging it is common to quantify the water content from radiographs.\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column23\">\n",
    "    \n",
    "\n",
    "\n",
    "- The transmission (gray level) $T=\\frac{I}{I_0}=e^{-\\mu \\cdot d}$\n",
    "    \n",
    "- The metric pixel area (pixel size)\n",
    "\n",
    "    \n",
    "The water volume is $V_{water}=pixelsize^2 \\cdot d$\n",
    "    \n",
    "    \n",
    "    \n",
    "Our uncertainties are now:\n",
    "- Standard deviation of the transmission (confidence interval)\n",
    "- The pixel size ... again\n",
    "    \n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column13\">\n",
    "    \n",
    "![](figures/pixel_volume.png)    \n",
    "    \n",
    "</div></div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba4d77b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Volume with uncertainty\n",
    "\n",
    "Let's assume we can trust the segmentation:\n",
    "- Thickness $d=5\\pm0.01~mm$\n",
    "- The pixel size is $p=43 \\pm 0.11~\\mu{}m$\n",
    "\n",
    "##### Volume uncertainty equation\n",
    "In this case, we know the uncertainty of $V=p^2\\cdot d$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0546ffa",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "_Derivation of the equation_\n",
    "\n",
    "The uncertainty of a multi product $\\prod^N_{i=1}x_i$ each with all $x_i$ uncorrelated and the uncertainty $\\sigma_{x_i}$, or more specific $x^2\\cdot y$ with $\\sigma_{x}$ $\\sigma_{y}$. \n",
    "\n",
    "Lets start with the derivative:  \n",
    "\n",
    "$\\frac{\\partial (x^2\\cdot y)}{\\partial x}=2xy$  \n",
    "\n",
    "and  \n",
    "\n",
    "$\\frac{\\partial (x^2\\cdot y)}{\\partial y}=x^2$\n",
    "\n",
    "Now the uncertainty is \n",
    "${\\sigma_{x^2\\cdot y}}^2 = \\left(2xy \\cdot \\sigma_x \\right)^2+ \\left(x^2 \\cdot \\sigma_y \\right)^2 $\n",
    "\n",
    "Dividing both sides by $x^2\\cdot y$ and taking the square root to get the relative uncertainty\n",
    "\n",
    "$\\frac{{\\sigma_{x^2\\cdot y}}}{x^2\\cdot y} = \\sqrt{\\frac{\\left(2xy \\cdot \\sigma_x \\right)^2}{\\left(x^2\\cdot y\\right)^2}+ \\frac{\\left(x^2 \\cdot \\sigma_y \\right)^2}{\\left(x^2\\cdot y\\right)^2} } = \\sqrt{4\\left(\\frac{\\sigma_x }{x}\\right)^2+ \\left(\\frac{\\sigma_y}{y}\\right)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5dc4a",
   "metadata": {},
   "source": [
    "Which gives the relative uncertainty \n",
    "$$\\frac{\\sigma_V}{V}=\\sqrt{4\\left(\\frac{\\sigma_{Pixelsize}}{Pixelsize}\\right)^2 + \\left(\\frac{\\sigma_{d}}{d}\\right)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66b801",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Computing the volume with uncertainty \n",
    "Plugging in the measurements in the equation:\n",
    "\n",
    "$$\\frac{\\sigma_V}{V}=\\sqrt{4\\left(\\frac{\\sigma_{Pixelsize}}{Pixelsize}\\right)^2 + \\left(\\frac{\\sigma_{d}}{d}\\right)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4145b0e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:13:45.262096Z",
     "start_time": "2023-04-16T11:13:45.214953Z"
    }
   },
   "outputs": [],
   "source": [
    "d           = 5.0      # mm\n",
    "d_uncertain = 0.01     # mm\n",
    "p           = 0.043    # mm\n",
    "p_uncertain = 0.00011  # mm\n",
    "\n",
    "V = p**2 * d\n",
    "\n",
    "rel_uncertainty = np.sqrt(4*(p_uncertain/p)**2 + (d_uncertain/d)**2)\n",
    "\n",
    "print('Volume = {0:0.3f} mm3 +/- {1:0.4f}%'.format(V,rel_uncertainty*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21648d56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:20:00.628131Z",
     "start_time": "2023-04-16T10:20:00.475402Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence of a segmentation\n",
    "_Freely from P. Moonen's talk at ICTMS2019_\n",
    "\n",
    "There are different ways to evaluate segmentation algorithm performance;\n",
    "_From lectures 2, 4, and 5_\n",
    "- Confusion matrix\n",
    "- ROC curve \n",
    "- Hit map\n",
    "\n",
    "... but they require a ground truth\n",
    "\n",
    "What if we want to know how well an image without ground truth was segmented?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbb8a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:09:55.529498Z",
     "start_time": "2023-04-16T15:09:55.464786Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b4b9c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence map without ground truth\n",
    "### Assume Gaussian noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e7316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:15:45.835645Z",
     "start_time": "2023-04-16T11:15:45.561725Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s0=1;\n",
    "noise = np.random.normal(size=[200,200])\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
    "ax[0].imshow(noise,cmap='gray')\n",
    "h,bins = np.histogram(noise.ravel(),bins=100)\n",
    "normh=h/h.sum()\n",
    "ax[1].fill(bins[:-1],normh,alpha=0.5,label='Noise histogram')\n",
    "x=np.linspace(-5,5,201)\n",
    "pdf = cm.gaussian(x,0,1)\n",
    "ax[1].plot(x,1.5*pdf/pdf.sum(),color=dcolors[1], label='Gaussian pdf')\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c3d6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Threshold between two Gaussian classes\n",
    "_From lecture 4_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdfa27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:15:47.280739Z",
     "start_time": "2023-04-16T11:15:47.086459Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=np.linspace(-6,6,1000)\n",
    "h0 = np.exp(-(x-1)**2/2)\n",
    "h1 = np.exp(-(x+1)**2/2)\n",
    "\n",
    "gamma=0.5\n",
    "\n",
    "# Visualization\n",
    "gidx = np.abs(x - gamma).argmin()\n",
    "plt.fill(x,h0,label='True positive',alpha=0.3,ec=dcolors[0],lw=2)\n",
    "plt.fill(x,h1,label='True negative',alpha=0.3,ec=dcolors[1],lw=2)\n",
    "\n",
    "plt.vlines([x[gidx]],ymin=0,ymax=1,color='magenta',label='Threshold $\\gamma$={0}'.format(gamma))\n",
    "\n",
    "plt.fill_between(x[:gidx],0,h0[:gidx],color=dcolors[2],label='False negative',alpha=0.3,ec=dcolors[2],lw=2)\n",
    "plt.fill_between(x[gidx:],0,h1[gidx:],color=dcolors[3],label='False positive',alpha=0.3,ec=dcolors[3],lw=2)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590401dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:03:52.898171Z",
     "start_time": "2023-04-16T14:03:52.658158Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute the confidence based on the class pdf's\n",
    "\n",
    "We want the probability mix of the classes for each gray level:\n",
    "1. Find the pdf for each class using Gaussian Mixture Models ([GMM](https://scikit-learn.org/stable/modules/mixture.html))\n",
    "2. Normalize\n",
    "    - Peak to one\n",
    "    - AOC is one\n",
    "3. For each gray level $x$ compute weights\n",
    "$$w_i(x)= pdf_i(x)$$\n",
    "for Gaussians $w_i(x)=e^{-\\frac{(x-\\mu_i)^2}{2 \\sigma_i^2}}$\n",
    "4. Then the confidence for class $i$ is \n",
    "$$c_i(x)=\\frac{w_i(x)}{\\sum_j w_j(x)}$$\n",
    "5. Create a confidence map using the segmented image to select $c_i$ for each pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f7ae4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What are the weights?\n",
    "\n",
    "In our algorithm we used $w_i(x)=e^{-\\frac{(x-\\mu_i)^2}{2 \\sigma_i^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a25c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T14:55:12.527337Z",
     "start_time": "2023-04-16T14:55:12.341691Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=np.linspace(-5,5,1000)\n",
    "g0=cm.gaussian(x,-1,1)\n",
    "g0m=g0.max()\n",
    "g0=g0/g0.max()\n",
    "g1=cm.gaussian(x,1,1)\n",
    "g1m=g1.max()\n",
    "g1=g1/g1.max()\n",
    "_,ax=plt.subplots(1)\n",
    "ax.plot(x,g0,label=r'Class 0')\n",
    "ax.plot(x,g1,label=r'Class 1')\n",
    "arrow = patches.FancyArrowPatch((xx,0), (xx,cm.gaussian(xx,1,1)/g1m),\n",
    "                                 mutation_scale=20,\n",
    "                                 color=dcolors[3],\n",
    "                                 arrowstyle='-|>',linewidth=2,\n",
    "                                label=r'$w_1$'\n",
    "                                )\n",
    "ax.add_patch(arrow);\n",
    "\n",
    "arrow = patches.FancyArrowPatch((xx,0), (xx,cm.gaussian(xx,-1,1)/g0m),\n",
    "                                 mutation_scale=20,\n",
    "                                 color=dcolors[2],\n",
    "                                 arrowstyle='-|>',linewidth=2,\n",
    "                                label=r'$w_0$'\n",
    "                                )\n",
    "ax.add_patch(arrow);\n",
    "\n",
    "ax.text(4,0.5,r'$c_0=\\frac{w_0}{w_0+w_1}=\\frac{0.3246}{0.3246+0.8825}=0.3207$',size=16)\n",
    "ax.text(4,0.25,r'$c_1=\\frac{w_1}{w_0+w_1}=\\frac{0.3246}{0.3246+0.8825}=0.8720$',size=16)\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('off');\n",
    "\n",
    "# print(cm.gaussian(xx,-1,1)/g0m,cm.gaussian(xx,1,1)/g1m,cm.gaussian(xx,-1,1)/g0m/(cm.gaussian(xx,-1,1)+cm.gaussian(xx,1,1)/g1m),cm.gaussian(xx,1,1)/g0m/(cm.gaussian(xx,-1,1)+cm.gaussian(xx,1,1)/g1m))lass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19837270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:26:14.065860Z",
     "start_time": "2023-04-16T11:26:13.839751Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Three phase segmentation\n",
    "\n",
    "Our test data\n",
    "- Three classes with $\\mu$=[-3,1,5]\n",
    "- Gaussian noise $~ \\mathcal{N}(\\mu, \\sigma=1.0)$\n",
    "- Unsharpness - Gaussian filter ($\\sigma$=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033ef53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T11:28:30.372493Z",
     "start_time": "2023-04-16T11:28:29.986137Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "ss = 1\n",
    "N = 20 \n",
    "m=np.array([-3,1,5])\n",
    "s=np.array([ss,ss,ss])\n",
    "xx=np.linspace(-10,10,1001)\n",
    "res = np.array([cm.multi_gaussian(x,m=m,s=s) for x in xx])\n",
    "\n",
    "img=np.repeat(np.repeat(np.array([[m[1],m[0]],[m[0],m[2]]]),N,axis=0),N,axis=1)\n",
    "seg=np.zeros(img.shape)\n",
    "fimg = flt.gaussian(img,sigma=1,preserve_range=True)\n",
    "for idx in range(len(m)):\n",
    "    seg[img==m[idx]]=idx\n",
    "\n",
    "nm = fimg+np.random.normal(loc=0,scale=ss,size=img.shape)\n",
    "\n",
    "cmap = cm.conf_map(nm,seg,m,s)\n",
    "\n",
    "fig,ax=plt.subplots(1,3,figsize=(15,5))\n",
    "ax=ax.ravel()\n",
    "ax[0].imshow(seg,cmap='gray')\n",
    "ax[0].set_title('Ground truth/segmentation')\n",
    "ax[1].imshow(fimg,cmap='gray')\n",
    "ax[1].set_title('Smooth image')\n",
    "ax[2].imshow(nm,cmap='gray')\n",
    "ax[2].set_title('Noisy image');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea131fed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The confidence maps for the segmenation\n",
    "_Here, we cheat by using the original shart image as segmented image_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea983ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T15:19:36.095720Z",
     "start_time": "2023-04-16T15:19:35.400813Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "seg=np.zeros(img.shape)\n",
    "fimg = flt.gaussian(img,sigma=1,preserve_range=True)\n",
    "for idx in range(len(m)):\n",
    "    seg[img==m[idx]]=idx\n",
    "\n",
    "fig,ax=plt.subplots(2,4,figsize=(15,8))\n",
    "\n",
    "ax=ax.ravel()\n",
    "ax[0].imshow(nm,cmap='gray')\n",
    "ax[0].set_title('Noisy image')\n",
    "\n",
    "for idx in range(3):\n",
    "    cmap = cm.conf_map(nm,seg,m,s,c=idx)\n",
    "    ax[idx+1].imshow(cmap,clim=[0,1])\n",
    "    ax[idx+1].set_title('Confidence class {}'.format(idx))\n",
    "\n",
    "ax[4].hist(nm.ravel(),bins=40);\n",
    "ax[5].axis('off')\n",
    "# ax[4].plot(xx,res);\n",
    "# ax[4].set_title('Normalized class distributions')\n",
    "\n",
    "cmap = cm.conf_map(nm,seg,m,s)\n",
    "ax[6].imshow(cmap,clim=[0,1])\n",
    "ax[6].set_title('Confidence map')\n",
    "xx,w = cm.conf_plot(m,s)\n",
    "for idx in range(len(m)) :\n",
    "    ax[7].plot(xx,w[idx]/np.sum(w,axis=0), label=\"C {}\".format(idx));\n",
    "    \n",
    "ax[7].legend()\n",
    "ax[7].set_title('Confidences');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df3051",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When does it matter?\n",
    "\n",
    "### High SNR images\n",
    "Edges have lowest confidence, i.e. most impact for\n",
    "- Perimeter\n",
    "- Turtosity\n",
    "- Network connectivity\n",
    "- Volumes of small items\n",
    "\n",
    "### Low SNR image\n",
    "Low confidence on most pixels!\n",
    "- All high-SNR issues\n",
    "- Porosity\n",
    "- Volumes\n",
    "- Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-wellington",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical experiments - Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-circumstances",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It often convenient to start with a simplified models for your experiments where most uncertainties are reduced. In particular here in this lecture we chose a simple model for the demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-clerk",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since most of the experiments in science are usually \n",
    "- specific, \n",
    "- noisy, \n",
    "- and often very complicated \n",
    "\n",
    "and are not usually good teaching examples.\n",
    "\n",
    "We go for a simple model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-despite",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Magic / Biased Coin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-charm",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Our model is the task to flip a coin and determine if it is a fair or loaded. The coin has two outcomes\n",
    "- head\n",
    "- or tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-response",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "You buy a _magic_ coin at a shop.\n",
    "\n",
    "__How many times do you need to flip it to _prove_ it is not fair?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-decade",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Next step is to describe an experiment strategy. Some examples are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-brave",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- If I flip it 10 times and another person flips it 10 times. Is that the same as 20 flips?\n",
    "- If I flip it 10 times and then multiply the results by 10. Is that the same as 100 flips?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-lyric",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As you already may have guessed, these are not the best assumtions, in particular not the second one. \n",
    "\n",
    "A different question is about collections of random variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-arthur",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "What if\n",
    "- I buy 10 coins and want to know which ones are fair, what do I do?\n",
    "\n",
    "<center><img src=\"figures/np_coin-toss.svg\" style='height:200px' /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-vatican",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/np_coin-toss.pdf\n",
    "---\n",
    "scale: 25%\n",
    "---\n",
    "Tossing a coin is a simple random process.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-female",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment: Magic / Weighted Coin\n",
    "\n",
    "\n",
    "1. Each coin represents a stochastic variable $\\mathcal{X}$ and each flip represents an observation $\\mathcal{X}_i$.\n",
    "1. The act of performing a coin flip $\\mathcal{F}$ is an observation $\\mathcal{X}_i = \\mathcal{F}(\\mathcal{X})$\n",
    "\n",
    "We normally assume:\n",
    "1. A _fair_ coin has an expected value of $E(\\mathcal{X})=\\frac{1}{2}$:\n",
    "    - 50% Heads, \n",
    "    - 50% Tails\n",
    "    \n",
    "1. An _unbiased_ flip(er) means  _each flip is independent of the others_\n",
    "$$P(\\mathcal{F}_1(\\mathcal{X})\\cdot{}\\mathcal{F}_2(\\mathcal{X}))= P(\\mathcal{F}_1(\\mathcal{X}))\\cdot{}P(\\mathcal{F}_2(\\mathcal{X}))$$\n",
    "\n",
    " - the expected value of the flip is the same as that of the coin\n",
    "$$ E\\left(\\prod_{i=0}^\\infty \\mathcal{F}_i(\\mathcal{X})\\right) = E(\\mathcal{X}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-writer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Model to Reality\n",
    "\n",
    "\n",
    "### Coin Flip\n",
    "\n",
    "1. Each flip gives us a small piece of information about \n",
    "    - the coin \n",
    "    - _and_ the flipper\n",
    "\n",
    "<br/>\n",
    "\n",
    "2. More flips provides more information\n",
    " - __Random / Stochastic variations__ in coin and flipper __cancel out__\n",
    " - __Systematic variations accumulate__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-intake",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Real experiment\n",
    "\n",
    "\n",
    "1. Each measurement tells us about: \n",
    "    - our sample, \n",
    "    - our instrument, \n",
    "    - _and_ our analysis      \n",
    "    \n",
    "2. More measurements provide more information:\n",
    " - __Random / Stochastic__ variations in _sample, instrument, and analysis_ __cancel out__\n",
    " - _Normally_, the analysis has very little to no stochastic variation\n",
    " - __Systematic variations__ accumulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-bicycle",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is also the reason why we want many repeated observations in an experiment. Repetitions are however expensive, they require time to perform the experiment and more material for the specimens. Therefore, a pragmatic choice must be made that balances the cost versus a reasonable amount of observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-phoenix",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A more complicated model\n",
    "\n",
    "Coin flips are very simple and probably difficult to match to another experiment. \n",
    "\n",
    "A very popular dataset for learning about such values beyond 'coin-flips' is called the [Iris dataset](http://archive.ics.uci.edu/ml/datasets/iris).  \n",
    "\n",
    "It covers:\n",
    "- a number of measurements \n",
    "- from different plants \n",
    "- and the corresponding species.\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/Iris.png\" style=\"height:300px\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-massachusetts",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's load the Iris Dataset\n",
    "\n",
    "Fisher, [The Use of Multiple Measurements in Taxonomic Problems](https://doi.org/10.1111/j.1469-1809.1936.tb02137.x), 1936"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-sellers",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The data set has information about dimensions of the flower anatomy for each of the three species. We load the data which is provided as a python dictionary and prepare a data frame for the table. You will get a more detailed introduction to pandas data frames later in this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-collective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:03.878839Z",
     "start_time": "2022-04-10T10:21:03.746466Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data              = load_iris()\n",
    "iris_df           = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "iris_df['target'] = data['target_names'][data['target']]\n",
    "iris_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-venue",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A first inspection of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-lexington",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We use a pair plot to inspect the table. Each target species is assigned a color to allow conclusions regarding clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-chapel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:07.129189Z",
     "start_time": "2022-04-10T10:21:04.329905Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p=sns.pairplot(iris_df, hue='target');\n",
    "plt.gcf().set_size_inches(9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-campaign",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the plot, we clearly see that one species (setosa) in general has other flower leaf dimensions than the other two. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-consistency",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Groups: Intraclass Correlation Coefficient\n",
    "\n",
    "The intraclass correlation coefficient basically looking at \n",
    "- how similar objects within a group are \n",
    "- compared to the similarity between groups\n",
    "\n",
    "### Group similarity\n",
    "How well are groups separated in a study\n",
    "- Low group similarity - overlapping histograms, harder to separate\n",
    "- High group similarity - separated histograms, easier to separate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-spring",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sepal width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-throw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Sepals are the green leaves of the flower bud. In this swarm plot we look at the width of the sepals and see that the variance of each class is about the same and also the the average width doesn't vary much. Under such conditions it is hard to separate the groups from each other and we are talking about a _low group similarity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-edwards",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:07.457753Z",
     "start_time": "2022-04-10T10:21:07.131126Z"
    },
    "format": "column",
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.swarmplot(data=iris_df, ax = ax1,\n",
    "               x='target', y='sepal width (cm)');ax1.set_title('Low Group Similarity');\n",
    "ax2.imshow(plt.imread('figures/FlowerAnatomy.png')); ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-cotton",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Petal length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-transcript",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T12:27:16.553488Z",
     "start_time": "2021-04-18T12:27:16.436708Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Petals are the colourful and beautiful leaves of the flower. In this swarm plot of the petal length we see that the petals are more clustered and the averages are well separated from each other. This is a case we know is easy to separate the groups and we are talkning about data with a _high group similarity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-subscription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:07.680139Z",
     "start_time": "2022-04-10T10:21:07.459065Z"
    },
    "format": "column",
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "g = sns.swarmplot(data=iris_df, ax=ax1,\n",
    "               x='target', y='petal length (cm)',size=4);g.set_title('High Group Similarity');\n",
    "ax2.imshow(plt.imread('figures/FlowerAnatomy.png')); ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-guide",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making quantitative statements\n",
    "### Intraclass Correlation Coefficient Definition\n",
    "$$ICC=\\frac{S_A^2}{S_A^2+S_W^2}$$\n",
    "\n",
    "where \n",
    "- The variance among groups or classes\n",
    "    $$S_A^2=\\mathrm{s}[\\mathrm{E}[x_{group}]]^2$$\n",
    "    - Estimate with the standard deviations of the mean values for each group  \n",
    " \n",
    "- The variance within groups or classes\n",
    "$$S_W^2=\\mathrm{E}[\\mathrm{s}[x_{group}]^2]$$\n",
    "    - Estimate with the average of standard deviations for each group\n",
    "\n",
    "__Interpretation__\n",
    "$$ICC=\\begin{cases}1&\\mbox{means 100 percent of the variance is between classes}\\\\0&\\mbox{means 0 percent of the variance is between classes}\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-consolidation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intraclass Correlation Coefficient: Values\n",
    "$$ICC=\\frac{S_A^2}{S_A^2+S_W^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-edmonton",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "When compute the ICC for sepal width and petal length, we see that the ICC confirms our first qualitative assessment about the group similiarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-uniform",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:07.936744Z",
     "start_time": "2022-04-10T10:21:07.682069Z"
    },
    "format": "tab",
    "hide_input": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def icc_calc(value_name, group_name, data_df):\n",
    "    data_agg = data_df.groupby(group_name).agg({value_name: ['mean', 'var']}).reset_index()\n",
    "    data_agg.columns = data_agg.columns.get_level_values(1)\n",
    "    S_w = data_agg['var'].mean()\n",
    "    S_a = data_agg['mean'].var()\n",
    "    print('{0}: S_w={1:0.02f}, S_a={2:0.2f}'.format(value_name,S_w,S_a))\n",
    "    return S_a/(S_a+S_w)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.swarmplot(data=iris_df, ax=ax1,\n",
    "               x='target', y='sepal width (cm)',size=3)\n",
    "ax1.set_title('Low Group Similarity\\nICC:{:2.1%}'.format(icc_calc('sepal width (cm)', 'target', iris_df)));\n",
    "\n",
    "sns.swarmplot(data=iris_df,ax=ax2, \n",
    "               x='target', y='petal length (cm)',size=3)\n",
    "ax2.set_title('High Group Similarity\\nICC:{:2.1%}'.format(icc_calc('petal length (cm)', 'target', iris_df)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-number",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparing Groups\n",
    "\n",
    "\n",
    "Once the reproducibility has been measured, it is possible to compare groups. \n",
    "\n",
    "The idea is to make a test to assess the likelihood that two groups are the same given the data\n",
    "\n",
    "1. List assumptions\n",
    "1. Establish a null hypothesis $\\mathcal{H}_0$\n",
    "    - Usually that both groups are the same  \n",
    " \n",
    "1. Calculate the probability of the observations given the truth of the null hypothesis\n",
    "    - Requires knowledge of probability distribution of the data\n",
    "    - Modeling can be exceptionally complicated\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93917a",
   "metadata": {},
   "source": [
    "### Outcomes for decision making\n",
    "\n",
    "<img src=\"figures/cases_of_decision_making.png\" style=\"height:400px\">\n",
    "\n",
    "With error probabilites:\n",
    "- $\\alpha$ - probability of Type I errors / significance level\n",
    "- $\\beta$ - probability of Type II errors\n",
    "\n",
    "From [Privitera 2017](http://www.sagepub.com/upm-data/40007_Chapter8.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-layer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loaded Coin example\n",
    "\n",
    "We have 1 coin from a magic shop.\n",
    "\n",
    "- Our assumptions are:\n",
    " - we flip and observe flips of coins accurately and independently\n",
    " - the coin is invariant and always has the same expected value\n",
    " \n",
    " \n",
    "- Our null hypothesis ($\\mathcal{H}_0$): the coin is unbiased $E(\\mathcal{X})=0.5$\n",
    "- we can calculate the likelihood of a given observation given the number of flips ([p-value](https://en.wikipedia.org/wiki/P-value))\n",
    "\n",
    "<center>\n",
    "<img src=\"figures/p-value.svg\" style=\"height:300px\"/>\n",
    "</center>\n",
    "\n",
    "How good is good enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-formation",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/p-value.pdf\n",
    "---\n",
    "scale: 100%\n",
    "---\n",
    "Explaining p-value with the normal distribution.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615ba19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing Groups: Student's T Distribution\n",
    "\n",
    "- Since we do not usually know our distribution very well \n",
    "- _or_ have enough samples to create a sufficient probability model\n",
    "\n",
    "### [Student T Distribution](http://en.wikipedia.org/wiki/Student's_t-distribution)\n",
    "We assume the distribution of our stochastic variable is normal (Gaussian) and the t-distribution provides an estimate for the mean of the underlying distribution based on few observations.\n",
    "\n",
    "- We estimate the likelihood of our observed values assuming they are coming from random observations of a normal process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-tuning",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Student T-Test](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
    "\n",
    "Incorporates this distribution and provides an easy method for assessing the likelihood that the two given set of observations are coming from the same underlying process (null hypothesis, $\\mathcal{H}_0$)\n",
    "\n",
    "- Assume unbiased observations\n",
    "- Assume normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-knight",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiple Testing Bias\n",
    "\n",
    "\n",
    "Back to the magic coin, let's assume we are trying to publish a paper, \n",
    "- we heard a p-value of < 0.05 (5%) was good enough. \n",
    "- Null-hypothesis ($\\mathcal{H}_0$): the coin is fair\n",
    "- That means if we get 5 heads we are good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-electronics",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability with increasing number of tosses\n",
    "\n",
    "$$ P = \\prod_i P(\\mathcal{F}_i(\\mathcal{X}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-colony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:10.039549Z",
     "start_time": "2022-04-10T10:21:10.011558Z"
    },
    "format": "column",
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from IPython.display import display\n",
    "all_heads_df = pd.DataFrame({'n_flips': [1, 4, 5]})\n",
    "all_heads_df['Probability of # Heads'] = all_heads_df['n_flips'].map(\n",
    "    lambda x: '{:2.1%}'.format(0.5**x))\n",
    "display(all_heads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-electric",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability with many experiments\n",
    "Let N friends make 5 tosses...\n",
    "\n",
    "$$P = \\overbrace{1-(\\underbrace{1-0.5^{N_{Tosses}}}_{\\mbox{Not getting 5 heads}})^{N_{Friends}}}^{\\mbox{Get 5 heads}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-ranch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:10.839113Z",
     "start_time": "2022-04-10T10:21:10.810977Z"
    },
    "format": "column",
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "friends_heads_df = pd.DataFrame({'n_friends': [1, 10, 20, 40, 80]})\n",
    "friends_heads_df['Probability of 5 Heads'] = friends_heads_df['n_friends'].map(\n",
    "    lambda n_friends: '{:2.1%}'.format((1-(1-0.5**5)**n_friends)))\n",
    "display(friends_heads_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-illustration",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Clearly this is not the case, otherwise we could keep flipping coins or ask all of our friends to flip until we got 5 heads and publish\n",
    "\n",
    "The p-value is only meaningful when the experiment matches what we did. \n",
    "- __We didn't say the chance of getting 5 heads ever was < 5%__\n",
    "- __We said is if we have__\n",
    "    - exactly 5 observations \n",
    "    - and all of them are heads \n",
    "    - the likelihood that a fair coin produced that result is <5%\n",
    "\n",
    "__There are many [methods](http://en.wikipedia.org/wiki/Multiple_comparisons_problem) to correct.__\n",
    "\n",
    "Most just involve scaling $p$: \n",
    "- The likelihood of a sequence of 5 heads in a row if you perform 10 flips is 5x higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-drawing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Testing Bias: Experiments\n",
    "\n",
    "\n",
    "This is very bad news for us. We have the ability to quantify all sorts of interesting metrics \n",
    "- cell distance to other cells\n",
    "- cell oblateness\n",
    "- cell distribution oblateness\n",
    "\n",
    "So, lets throw them all into a magical statistics algorithm and push the __publish__ button\n",
    "\n",
    "\n",
    "With our p value of less than 0.05 and a study with 10 samples in each group, how does increasing the number of variables affect our result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed442d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's look at multiple observations\n",
    "\n",
    "We make five random variables with ten observations of a uniform distribution in the interval $\\pm$1\n",
    "\n",
    "$$var\\_i \\in \\mathcal{U}(-1,1)$$\n",
    "\n",
    "and make two groups '1' and '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-eugene",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:11.873867Z",
     "start_time": "2022-04-10T10:21:11.834517Z"
    },
    "format": "column",
    "hide_input": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('precision', 2)\n",
    "np.random.seed(2017)\n",
    "\n",
    "def random_data_maker(rows, cols):\n",
    "    data_df = pd.DataFrame(\n",
    "        np.random.uniform(-1, 1, size=(rows, cols)),\n",
    "        columns=['Var_{:02d}'.format(c_col) for c_col in range(cols)])\n",
    "    data_df['Group'] = [1]*(rows-rows//2)+[2]*(rows//2)\n",
    "    return data_df\n",
    "\n",
    "rand_df = random_data_maker(10, 5)\n",
    "\n",
    "rand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-state",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute p-values for the table\n",
    "\n",
    "The Student-t test is computed using the python function \n",
    "```python\n",
    "scipy.stats import ttest_ind\n",
    "\n",
    "ttest_ind(var_i[Group==1],var_i[Group==2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-yesterday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:52:34.616462Z",
     "start_time": "2021-04-21T07:52:34.583981Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is a two-sided test for the null hypothesis that two independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default.\n",
    "\n",
    "Here, we compute the p-values for the table we just created. The variables with p-values less than 0.05 are marked with yellow.\n",
    "\n",
    "In the following example we compare the two groups of each random variable to determine if they are significantly different.\n",
    "\n",
    "Essentially $ttest\\_ind(var_i[Group==1],var_i[Group==2])$\n",
    "\n",
    "We expect the two parts to be the same as all values are generated using the same random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-building",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:12.643038Z",
     "start_time": "2022-04-10T10:21:12.542888Z"
    },
    "format": "column",
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def show_significant(in_df, cut_off=0.05):\n",
    "    return in_df.sort_values('P-Value').style.apply(lambda x: ['background-color: yellow' if v<cut_off else '' for v in x])\n",
    "\n",
    "def all_ttest(in_df):\n",
    "    return pd.DataFrame(\n",
    "        {'P-Value': {c_col: ttest_ind(\n",
    "            a=in_df[in_df['Group'] == 1][c_col],\n",
    "            b=in_df[in_df['Group'] == 2][c_col]\n",
    "        ).pvalue\n",
    "            for c_col in\n",
    "            in_df.columns if 'Group' not in c_col}})\n",
    "\n",
    "\n",
    "show_significant(all_ttest(rand_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-sapphire",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A larger table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-generation",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now, let's create a larger table with 150 rows and 20 independent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-lender",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:13.180848Z",
     "start_time": "2022-04-10T10:21:13.127672Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "show_significant(all_ttest(random_data_maker(150, 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-findings",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repeating the measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-stock",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We saw with the coin tossing that the probability to detect the event we are looking for increased with the number of repeated independent measurements (friends tossing coins).\n",
    "\n",
    "Let's see what happens when we do the the same with our table of experiments. First, we must generate the data. We will try using tables with 1 to 150 variable and  100 observations. Each measurement will be repeated 50 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-powder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:53.367609Z",
     "start_time": "2022-04-10T10:21:13.723422Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from tqdm import notebook # progressbar\n",
    "out_list = []\n",
    "for n_vars in notebook.tqdm(range(1, 150, 10)):\n",
    "    for _ in range(50):\n",
    "        p_values = all_ttest(random_data_maker(100, n_vars)).values\n",
    "        out_list += [{'Variables in Study': n_vars,\n",
    "                      'Significant Variables Found': np.sum(p_values < 0.05),\n",
    "                     'raw_values': p_values}]\n",
    "var_found_df = pd.DataFrame(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-stamp",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:53.592401Z",
     "start_time": "2022-04-10T10:21:53.369453Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(12,4))\n",
    "sns.stripplot(data=var_found_df, x='Variables in Study', y='Significant Variables Found');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-producer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize the results differently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-singing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T08:08:16.592761Z",
     "start_time": "2021-04-21T08:08:16.558102Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The strip plot we just used gets cluttered when we have too many observations. A different way to show the results is to use a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-merit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:53.867670Z",
     "start_time": "2022-04-10T10:21:53.593892Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=var_found_df,\n",
    "            x='Variables in Study', y='Significant Variables Found');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-plain",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Testing Bias: Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-resolution",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We saw that increasing the number of tests also increases the probability of detection. This is missleading and needs to be corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-train",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using the simple correction factor (number of tests performed) as proposed by Bonferroni, we can make the significant findings constant again. \n",
    "$$ p_{\\mbox{cutoff}} = \\frac{0.05}{\\textrm{Number of Tests}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64f79f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This comes from the familywise error \n",
    "$$\\bar{\\alpha}=1-\\left(1-\\alpha_{\\mbox{per comparison}}\\right)^m$$\n",
    "\n",
    "where $m$ is the number of hypotheses tested. Then, with Boole's inequality we have\n",
    "\n",
    "$$\\bar{\\alpha}\\leq{} m\\cdot \\alpha_{\\mbox{per comparison}}$$\n",
    "\n",
    "Which leads to the Boniferroni correction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-court",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:54.114814Z",
     "start_time": "2022-04-10T10:21:53.869785Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,figsize=(5,4))\n",
    "var_found_df['Corrected Significant Count'] = var_found_df['raw_values'].map(lambda p_values: \n",
    "                                                                             np.sum(p_values<0.05/len(p_values)))\n",
    "\n",
    "var_found_df.groupby('Variables in Study').agg('mean').reset_index().plot('Variables in Study', [\n",
    "    'Significant Variables Found',\n",
    "    'Corrected Significant Count'\n",
    "],ax=ax);\n",
    "plt.title('Effect of significance correction');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-asian",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### It this correction factor sufficient?\n",
    "So no harm done there we just add this correction factor right?\n",
    "\n",
    "Well, what if we have exactly one variable with shift of 1.0 standard deviations from the other. \n",
    "\n",
    "In a dataset where we check $n$ variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-world",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:54.488186Z",
     "start_time": "2022-04-10T10:21:54.116250Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "table_df = random_data_maker(50, 10)\n",
    "really_different_var = np.concatenate([\n",
    "    np.random.normal(loc=0, scale=1.0, size=(table_df.shape[0]//2)),\n",
    "    np.random.normal(loc=1, scale=1.0, size=(table_df.shape[0]//2))\n",
    "])\n",
    "table_df['Really Different Var'] = really_different_var\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.hist(table_df.query('Group==1')['Really Different Var'], np.linspace(-5, 5, 20), label='Group 1', alpha=0.5);\n",
    "ax1.vlines(0,ymin=0,ymax=8.5,label='$\\overline{x}_1=0$')\n",
    "ax1.hist(table_df.query('Group==2')['Really Different Var'], np.linspace(-5, 5, 20), label='Group 2', alpha=0.5);\n",
    "ax1.vlines(1,ymin=0,ymax=8.5,color='blue',label='$\\overline{x}_2=1$')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-harbor",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### Run many tests\n",
    "\n",
    "We run 200 tests with two variables with $\\mathcal{N}(0,1)$ and $\\mathcal{N}(1,1)$ and compute the p-values for each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-blond",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:54.559321Z",
     "start_time": "2022-04-10T10:21:54.489681Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "out_p_value = []\n",
    "for _ in range(200):\n",
    "    out_p_value += [ttest_ind(np.random.normal(loc=0, scale=1.0, size=(table_df.shape[0]//2)),\n",
    "          np.random.normal(loc=1, scale=1.0, size=(table_df.shape[0]//2))).pvalue]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-purse",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "When we look at the histograms of p-values scale by the number of variables in the test we see that there is a greater probability to accept the null-hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-height",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:55.378483Z",
     "start_time": "2022-04-10T10:21:54.560680Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for c_ax, var_count in zip(m_axs.flatten(), np.linspace(1, 140, 9).astype(int)):\n",
    "    c_ax.hist(np.clip(np.array(out_p_value)*var_count, 0.01, 0.3), np.linspace(0.01, 0.3, 30))\n",
    "    c_ax.set_ylim(0, 100)\n",
    "    c_ax.set_title('p-value after multiple correction\\n for {} variables'.format(var_count))\n",
    "    \n",
    "\n",
    "m_axs[0,1].annotate(\"Collected tail counts\", xy=(0.28, 25), xytext=(0.15, 40), arrowprops=dict(arrowstyle=\"->\",color=\"black\"),fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-parent",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The likelihood to find a different variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-initial",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The scaling by the number of variables means that we are less likely to reject the null hypothesis. So, what is the likelihood?\n",
    "\n",
    "We count the number of the p-values less than 0.05 to compute the likelihood of detecting a really different variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-application",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-10T10:21:55.557612Z",
     "start_time": "2022-04-10T10:21:55.379904Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "var_find_df = pd.DataFrame({'Variables': np.linspace(1, 100, 30).astype(int)})\n",
    "var_find_df['Likelihood of Detecting Really Different Variable'] = var_find_df['Variables'].map(\n",
    "    lambda var_count: np.mean(np.array(out_p_value)*var_count<0.05)\n",
    ")\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15, 5))\n",
    "var_find_df.plot('Variables', 'Likelihood of Detecting Really Different Variable', ax=ax1)\n",
    "ax1.set_ylabel('% Likelihood');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-airfare",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here, we see that the likelihood is very low for many varibles. A reason in that we are working on a limited number of samples and split these on an incresing number of varibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-swaziland",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sensitivity to anlysis parameters\n",
    "We have a workflow to analyze _shape_ and _thickness_ of items in an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-challenge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T10:34:11.824735Z",
     "start_time": "2023-04-16T10:34:11.301412Z"
    },
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "dot.node('Raw images',color='limegreen'),        dot.node('Gaussian filter', color='lightblue')\n",
    "dot.node('sigma=0.5', color='gray',shape='box'), dot.node('3x3 Neighbors', color='gray',shape='box')\n",
    "dot.node('Threshold', color='lightblue'),        dot.node('100', color='gray',shape='box')\n",
    "dot.node('Thickness analysis',color='hotpink'),  dot.node('Shape analysis',color='hotpink')\n",
    "dot.node('Input',color='limegreen'),        dot.node('Functions', color='lightblue')\n",
    "dot.node('Parameters', color='gray',shape='box'),dot.node('Output',color='hotpink')\n",
    "\n",
    "dot.edge('Raw images', 'Gaussian filter'),    dot.edge('sigma=0.5', 'Gaussian filter')\n",
    "dot.edge('3x3 Neighbors', 'Gaussian filter'), dot.edge('Gaussian filter','Threshold')\n",
    "dot.edge('Threshold', 'Thickness analysis'),  dot.edge('Threshold', 'Shape analysis')\n",
    "dot.edge('100','Threshold')\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c0a886",
   "metadata": {},
   "source": [
    "Three parameters can be controlled:\n",
    "- Gaussian filter: $\\sigma$ and _neighborhood size_\n",
    "- Threshold level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-gibson",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter Sweep\n",
    "\n",
    "The way we do this is usually a parameter sweep which means \n",
    "- taking one (or more) parameters \n",
    "- and varying them between the reasonable bounds (judged qualitatively).\n",
    "\n",
    "<img src=\"figures/parameter_sweep.png\" style=\"height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-think",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The outcome of a parameter sweep can look like in the figure below.\n",
    "```{figure} figures/parameter_sweep.png\n",
    "---\n",
    "scale: 50%\n",
    "name: fig_parametersweep\n",
    "---\n",
    "Volume measurements for different thresholds\n",
    "```\n",
    "We can see that the volume is generally decreasing when the threshold increases. Still, it seems that the volume is not that sensitive to the choice of threshold. Variations in the order of about 50 voxels. That would correspond to a radius change from 6.3 to 6.7 for the equivalent spheres. On the other hand, this minor change could be the difference between separated or touching objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-parish",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Is it always the same?\n",
    "<table><tr><td>\n",
    "<img src=\"figures/parameter_sweep_volume.png\" style=\"height:400px\"/></td>\n",
    "<td><img src=\"figures/parameter_sweep_orientation.png\" style=\"height:400px\"/></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-virginia",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The jittered scatter plot in {numref}`fig {number} <fig_parametersweep>` makes it hard to see the distribution of the measurements. A violin plot as in the figure below is a histogram view of the data that allows stacking for different observations.\n",
    "\n",
    "```{figure} figures/parameter_sweep_volume.png\n",
    "---\n",
    "scale: 50%\n",
    "name: fig_parameters_violin\n",
    "---\n",
    "A violin plot of the volume data.\n",
    "```\n",
    "\n",
    "Now, what happens if we look at a different item metric like the orientation of the items. \n",
    "```{figure} figures/parameter_sweep_orientation.png\n",
    "---\n",
    "scale: 50%\n",
    "name: fig_parameters_orientation\n",
    "---\n",
    "Scatter plot of the orientation of the items.\n",
    "```\n",
    "Here, we see a similar trend as we saw with the volume. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-notebook",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sensitivity\n",
    "\n",
    "### Control system theory\n",
    "Sensitivity is defined as \n",
    "- the change in the value of an output \n",
    "- against the change in the input.\n",
    "\n",
    "\n",
    "$$ S = \\frac{|\\Delta \\textrm{Metric}|}{|\\Delta \\textrm{Parameter}|} $$\n",
    "\n",
    "### Image processing\n",
    "Such a strict definition is not particularly useful for image processing since \n",
    "- a threshold has a unit of intensity and \n",
    "- a metric might be volume which has $m^3$ \n",
    "\n",
    "$\\rightarrow$ the sensitivity becomes volume per intensity!\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-population",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practical Sensitivity\n",
    "\n",
    "A more common approach is to estimate the variation in this parameter between images or within a single image (automatic threshold methods can be useful for this) and define the sensitivity based on this variation.\n",
    "\n",
    "It is also common to normalize it with the mean value so the result is a percentage.\n",
    "\n",
    "$$ S = \\frac{max(\\textrm{Metric})-min(\\textrm{Metric})}{avg(\\textrm{Metric})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-anxiety",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sensitivity: Real Measurements\n",
    "\n",
    "\n",
    "In this graph it is magnitude of the slope. The steeper the slope the more the metric changes given a small change in the parameter\n",
    "\n",
    "<img src=\"figures/sensitivity_counts.png\" style=\"height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-budget",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/sensitivity_counts.png\n",
    "---\n",
    "width: 8cm \n",
    "---\n",
    "Sensitivity measurement to measure how sensitive the object count is to the choice of the threshold.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-buyer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sensitivity: compare more than one variable\n",
    "Comparing Different Variables we see that \n",
    "- the best (lowest) value for the count sensitivity \n",
    "- is the highest for the volume and anisotropy. \n",
    "\n",
    "<img src=\"figures/sensitivity_compare.png\" style=\"height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-dimension",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/sensitivity_compare.png\n",
    "---\n",
    "width: 8cm \n",
    "name: fig_comparesensitivity\n",
    "---\n",
    "Sensitivity comparison for different metrics (Anisotropy, Count, Volume) to the choice of the threshold.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-harmony",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### A contradiction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-culture",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We see in {numref}`Fig <number> fig_comparesensitivity` that two parameters with relatively low sensitivity variations behave the same while the last one (_count_) fluctuates a lot with the threshold choice. Which one we use to guide our segmentation ultimately depends on the objective of the investigation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-acting",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducibility\n",
    "A very broad topic with plenty of sub-areas and deeper meanings. We mean two things by reproducibility\n",
    "\n",
    "### Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-button",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Everything for analysis + taking a measurement several times (noise and exact alignment vary each time) does not change the statistics _significantly_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-officer",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- No sensitivity to mounting or rotation\n",
    "- No sensitivity to noise\n",
    "- No dependence on exact illumination\n",
    "\n",
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-camping",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The process of going from images to numbers is detailed in a clear manner that __anyone__, __anywhere__ could follow and get the exact (within some tolerance) same numbers from your samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-parking",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- No platform dependence\n",
    "- No proprietary or \"in house\" algorithms\n",
    "- No manual *clicking*, *tweaking*, or *copying*\n",
    "- A single script to go from image to result\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93752056",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Doing analyses in a disciplined manner\n",
    "\n",
    "<img src=\"figures/diciplined_steps.svg\" style=\"height:300\" />\n",
    "\n",
    " - fixed, well-defined, steps\n",
    " - easy to regenerate results\n",
    " - no _magic_\n",
    " - documentation\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414c406",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advantages of a diciplined workflow\n",
    "\n",
    "#### Having everything automated\n",
    "\n",
    " - 100 samples is as easy as 1 sample\n",
    " - Some intitial extra effort pays off\n",
    " \n",
    "#### Being able to adapt and reuse analyses\n",
    "\n",
    " - one really well working script\n",
    " - modify parameters to address e.g.\n",
    "     - different types of cells\n",
    "     - different regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-cleveland",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reproducible Analysis\n",
    "\n",
    "Since we will need to perform the same analysis many times to understand how reproducible it is.\n",
    "\n",
    "- Notebooks are good to develop and document analysis workflow.\n",
    "- The basis for reproducible analysis are scripts and macros. \n",
    "\n",
    "### With python scripts\n",
    "```python\n",
    "# #!/$PYTHONPATH/python\n",
    "import sys\n",
    "from myAnalysis import analysisScript # some analysis script you implemented\n",
    "\n",
    "imageFile = sys.argv[0] # File name from command line\n",
    "\n",
    "threshold = 130\n",
    "analysisScript(fname=imageFile, threshold = threshold)\n",
    "```\n",
    "\n",
    "\n",
    "### or Matlab, ImageJ, or R\n",
    "```bash\n",
    "IMAGEFILE=$1\n",
    "THRESHOLD=130\n",
    "matlab -r \"inImage=$IMAGEFILE; threshImage=inImage>$THRESHOLD; analysisScript;\"\n",
    "```\n",
    "- __or__ \n",
    "```java -jar ij.jar -macro TestMacro.ijm blobs.tif```\n",
    "- __or__\n",
    "```Rscript -e \"library(plyr);...\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-backing",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predicting and Validating - main categories\n",
    "\n",
    "<img src=\"figures/MLalgorithms.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-projector",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are plenty machine-learning techniques available. Each one dedicated to a specific type of problem and data collection.  \n",
    "\n",
    "```{figure} figures/MLalgorithms.png\n",
    "---\n",
    "scale: 100%\n",
    "name: fig_mlcheatsheet\n",
    "---\n",
    "A cheat sheet to identify the best machine learning technique for your problem.\n",
    "```\n",
    "\n",
    "{numref}`Fig <number> fig_mlcheatsheet` provides a guide to find the correct method for your problem.\n",
    "\n",
    "A common task independent of which method you chose, it that you have to validate your processing workflow. This is important to be able to tell when and to what degree you can trust your workflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-covering",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Borrowed from http://peekaboo-vision.blogspot.ch/2013/01/machine-learning-cheat-sheet-for-scikit.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-parts",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "Basically all of these are ultimately functions which map inputs to outputs. \n",
    "\n",
    "### The input could be \n",
    "\n",
    "- an image\n",
    "- a point\n",
    "- a feature vector\n",
    "- or a multidimensional tensor\n",
    "\n",
    "### The output is\n",
    "\n",
    "- a value (regression)\n",
    "- a classification (classification)\n",
    "- a group (clustering)\n",
    "- a vector / matrix / tensor with _fewer_ degrees of input / less noise as the original data (dimensionality reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-russell",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-jurisdiction",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The most serious problem with machine learning and such approachs is overfitting your model to your data. Particularly as models get increasingly complex (random forest, neural networks, deep learning, ...), it becomes more and more difficult to apply common sense or even understand exactly what a model is doing and why a given answer is produced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-today",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Training a model like:\n",
    "```python\n",
    "magic_classifier = {}\n",
    "# training\n",
    "magic_classifier['Dog']  = 'Animal'\n",
    "magic_classifier['Bob']  = 'Person'\n",
    "magic_classifier['Fish'] = 'Animal'\n",
    "```\n",
    "\n",
    "Now use this classifier, on the training data it works really well\n",
    "\n",
    "```python\n",
    "magic_classifier['Dog']  == 'Animal' # true, 1/1 so far!\n",
    "magic_classifier['Bob']  == 'Person' # true, 2/2 still perfect!\n",
    "magic_classifier['Fish'] == 'Animal' # true, 3/3, wow!\n",
    "```\n",
    "\n",
    "On new data it doesn't work at all, it doesn't even execute.\n",
    "\n",
    "```python\n",
    "magic_classifier['Octopus'] == 'Animal' # exception?! but it was working so well\n",
    "magic_classifier['Dan']     == 'Person' # exception?! \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-estate",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This example appeared to be a perfect trainer for mapping names to animals or people, but it just memorized the inputs and reproduced them at the output and so didn't actually learn anything, it just copied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-capture",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-stand",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Relevant for each of the categories, but applied in a slightly different way depending on the group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-tours",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The idea is to divide the dataset into groups called \n",
    "- ideally training, \n",
    "- validation, \n",
    "- and testing. \n",
    "\n",
    "The analysis is then \n",
    "\n",
    "- developed on __training__\n",
    "- iteratively validated on __validation__\n",
    "- ultimately tested on __testing__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-romance",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Presenting the results - bringing out the message\n",
    "\n",
    "In the end you will want to present your results\n",
    "\n",
    "<img src=\"figures/presentationmodes.svg\" style=\"height:400px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-jewelry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T11:43:42.780633Z",
     "start_time": "2021-04-17T11:43:42.557223Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/presentationmodes.pdf\n",
    "---\n",
    "scale: 100%\n",
    "---\n",
    "Different ways to present your data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-nothing",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "One of the biggest problems with _big_ sciences is trying to visualize a lot of heterogeneous data. \n",
    "\n",
    "- Tables are difficult to interpret\n",
    "- 3D Visualizations are very difficult to compare visually \n",
    "- Contradictory necessity of simple single value results and all of the data to look for trends and find problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-hayes",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purpose of the visualization\n",
    "\n",
    "You visualize your data for different reasons:\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column35\">\n",
    "        \n",
    "1. __Understanding and exploration__\n",
    "- Small and known audience (you and colleagues)\n",
    "- High degree of understanding of specific topic.  \n",
    "    \n",
    "2. __Presenting your results__\n",
    "- Wider and sometimes unknown audience (reader of paper, person listening to presentation)\n",
    "- At best general understanding of the topic.\n",
    "    \n",
    "</div>\n",
    "<div class=\"column25\">\n",
    "<img src=\"figures/Knaflic_audience.png\" style='height:400px'/> \n",
    "    \n",
    "    \n",
    "from [Knaflic 2015](https://doi.org/10.1002/9781119055259)\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-blocking",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/Knaflic_audience.png\n",
    "---\n",
    "scale: 80%\n",
    "---\n",
    "The level of detail in a presentation depends on the medium it is presented [Knaflic 2015](https://doi.org/10.1002/9781119055259).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-appendix",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bad Graphs\n",
    "\n",
    "<div class=\"row\">\n",
    "<div class=\"column35\">\n",
    "\n",
    "There are too many graphs which say:\n",
    "\n",
    "- *my data is very complicated*\n",
    "    \n",
    "- *I know how to use __ toolbox in Python/Matlab/R/Mathematica*\n",
    "    \n",
    "- Most programs by default make poor plots\n",
    "    \n",
    "- Good visualizations takes time to produce\n",
    "    \n",
    "</div>\n",
    "<div class=\"column25\">\n",
    "<img src=\"figures/scientific_paper_graph_quality_2x.png\" style='height:300px'/>\n",
    "\n",
    "[xkcd](https://xkcd.com/1945)\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-fraud",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```{figure} figures/scientific_paper_graph_quality_2x.png\n",
    "---\n",
    "scale: 60%\n",
    "---\n",
    "This cartoon from [XKCD](https://xkcd.com/1945/) highlights a problem with the access to software making it too easy to produce a graph or illustration.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-israel",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some bad examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-blogger",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are plenty examples on how you shouldn't present your data. The problem is in general that there is way too much information that needs to be predigestend before it is ready to any audience.\n",
    "```{figure} figures/badvisualizations.png\n",
    "---\n",
    "scale: 100%\n",
    "---\n",
    "Four examples of how _not_ to present your data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-swaziland",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src='figures/badImage1.png' style='height:400px'/></td><td><img src='figures/badPlot4.png' style='height:400px' /></td><td><img src='figures/badImage3.png' style='height:4 00px' /></td><td><img src='figures/badImage2.png' style='height:400px' /></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-model",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to improve - Key Ideas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-oliver",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There is a need to consciously prepare your figures to bring your message to the audience in an understandable way. The first step is to ask yourself the following questions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-amateur",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "1. What is my message? \n",
    "1. Does the graphic communicate it clearly?\n",
    "1. Is a graphic representation really necessary?\n",
    " - Does every line / color serve a purpose?\n",
    " - Pretend ink is very expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-external",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Keep this in mind every time you create a figure and you will notice that after while you will have a tool set that makes it easier and faster to produce well thought figures that clearly brings out you message to your audience. \n",
    "\n",
    "Personally, I always write scripts to produce each plot of a publication. This makes it easier to revise the manuscript in a reproducible and efficient manner. The first implementation may take longer, but the revision is done in no time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-senegal",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Some literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-texas",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If you want to read more about how to work with data visualization. I can recommend these:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-civilian",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Knaflic, [Storytelling with Data: A Data Visualization Guide for Business Professionals](https://doi.org/10.1002/9781119055259), 2015\n",
    "\n",
    "- Few, [Should data visualization always be beautiful?](https://www.perceptualedge.com/blog/?p=1169), 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-relationship",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple Rules\n",
    "\n",
    "1. Never use 3D graphics when it can be avoided (unless you want to be deliberately misleading)\n",
    "![Dumb 3d](figures/3dplot.png)\n",
    "1. Pie charts can also be hard to interpret\n",
    "1. Background color should almost always be white (not light gray)\n",
    "1. Use color palettes adapted to human visual sensitivity \n",
    "1. Use colors and transparency smart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-allen",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grammar of Graphics\n",
    "\n",
    "\n",
    "### What is a grammar?\n",
    "- Set of rules for constructing and validating a sentence\n",
    "- Specifies the relationship and order between the words constituting the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-acoustic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does grammar apply to graphics?\n",
    "If we develop a consistent way of \n",
    "- expressing graphics (sentences) \n",
    "- in terms of elements (words) \n",
    "we can compose and decompose graphics easily\n",
    "\n",
    "\n",
    "The most important modern work in graphical grammars is [\"The Grammar of Graphics\"](https://doi.org/10.1007/0-387-28695-0)  by Wilkinson, Anand, and Grossman (2005). \n",
    "\n",
    "This work built on earlier work by Bertin (1983) and proposed a grammar that can be used to describe and construct a wide range of statistical graphics.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-blair",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grammar Explained\n",
    "\n",
    "Normally we think of plots in terms of some sort of data which is fed into a plot command that produces a picture\n",
    "- In Excel you select a range and plot-type and click \"Make\"\n",
    "- In Matlab you run ```plot(xdata,ydata,color/shape)``` \n",
    "\n",
    "1. These produces entire graphics (sentences) or at least phrases in one go and thus abstract away from the idea of grammar. \n",
    "1. If you spoke by finding entire sentences in a book it would be very ineffective, it is much better to build up word by word\n",
    "\n",
    "<img src=\"figures/niceplot.svg\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-synthetic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grammar\n",
    "\n",
    "Separate the graph into its component parts\n",
    "\n",
    "<table>\n",
    "<cols width=\"300px\" />\n",
    "<tr><th>Data mapping</th><th>Points</th><th>Axes/Coordinate system</th><th>Labels/annotation</th></tr>\n",
    "<tr>\n",
    "<td>$\\begin{cases}var1 \\rightarrow x\\\\var2 \\rightarrow y\\end{cases}$</td>\n",
    "<td><img src=\"figures/niceplot_points.png\" style=\"height:300px\" /></td>\n",
    "<td><img src=\"figures/niceplot_axes.png\"   style=\"height:300px\" /></td>\n",
    "<td><img src=\"figures/niceplot_annotations.png\" style=\"height:300px\" /></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Construct graphics by focusing on each portion independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-ability",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Figure decorations\n",
    "\n",
    "Besides the data you also need to provide annotating items to the visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-mother",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It may seem unnescessary to list these annotations, but it happens too often that they are missing. This leaves the observers wondering about what they see in the figure. It is true that it takes a little more time to add annotation to your figure. Sometimes, you may think that the plot is only for your own understanding and you don't need to waste the time on making it complete. Still, in the next moment it finds its way to the presentation and then all of a sudden it is offical...\n",
    "\n",
    "Annotations are fundamental features of figures and available in any plotting library. In some cases you have to look a little longer to find them or write a little more code to use them, but they are there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-weapon",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Plots\n",
    "- Curve legend - telling what each curve represents.\n",
    "- Axis labels - tellning what information you see on each axis.\n",
    "- Figure title - if you use multiples plots in the same figure.\n",
    "\n",
    "#### Images\n",
    "- Color bar - to tell how the colors are mapped to the values.\n",
    "- Scale bar - to tell the size of the object in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-spring",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Color maps revisited\n",
    "Choosing the right color is a science.\n",
    "\n",
    "<img src=\"figures/colormapselection.png\" style=\"height:700px\" />\n",
    "\n",
    "[Crameri, F., et al. (2020)]( https://doi.org/10.1038/s41467-020-19160-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-steel",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The choice depends on the type of data you want to present and how humans percieve different colors. Some combinations make it easier to highlight relevant features in the images. Still, you have to be cautious not put too much a priori information into the color map. \n",
    "\n",
    "```{figure} figures/colormapselection.png\n",
    "---\n",
    "scale: 75%\n",
    "---\n",
    "Crameri et al. developed this decision flow chart to help you decide which type of color map is best suited for your data.\n",
    "```\n",
    "\n",
    "Visualization toolboxes provide a great collection of colormaps as we have seen several times already in this course. There are however cases when you have to define your own color map. An example is the colormap we created last week to be able to identify each item in a watershed segmented image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-bankruptcy",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is my message?\n",
    "Plots to \"show the results\" or \"get a feeling\" are usually not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-carnival",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T06:55:04.412578Z",
     "start_time": "2021-04-22T06:55:03.196940Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Some data\n",
    "xd = np.random.rand(80)\n",
    "yd = xd + np.random.rand(80)\n",
    "zd = np.random.rand(80)\n",
    "\n",
    "df = pd.DataFrame(dict(x=xd,y=yd,z=zd))\n",
    "ggplot(df,aes(x='x',y='y')) + geom_point();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-wichita",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Focus on a single, simple message\n",
    "\"X is a little bit correlated with Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-function",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T06:55:04.733241Z",
     "start_time": "2021-04-22T06:55:04.414128Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y')) \n",
    " + geom_point() \n",
    " + geom_smooth(method=\"lm\")\n",
    "# + coord_equal() \n",
    " + labs(title=\"X is weakly correlated with Y\")\n",
    " + theme_bw(12) );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-budapest",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Does my graphic communicate it clearly?\n",
    "\n",
    "Too much data makes it very difficult to derive a clear message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-patch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T09:07:06.421989Z",
     "start_time": "2021-04-22T09:07:05.784208Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xd = np.random.rand(5000)\n",
    "yd = (xd-0.5)*np.random.rand(5000)\n",
    "\n",
    "df = pd.DataFrame(dict(x=xd,y=yd))\n",
    "(ggplot(df,aes(x='x',y='y')) \n",
    "# + geom_point()\n",
    " + geom_point( alpha = 0.1 )\n",
    " + coord_equal()\n",
    " + theme_bw(20));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-rehabilitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T07:56:19.273966Z",
     "start_time": "2021-04-19T07:56:19.271244Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We have earlier used transparency to better visualize dense scatter plots. You can see the effect by setting the alpha parameter to geom_point. Using transparency is a qualitative way of showing higher density in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-scottish",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reduce the data\n",
    "Filter and reduce information until it is extremely simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-variance",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this plot we create a density count view of the data by downsampling the grid and count the amount of points in each bin. It is related to a histogram but it count in space instead of in the intensity levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-burlington",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T06:55:05.494917Z",
     "start_time": "2021-04-22T06:55:05.096113Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y'))\n",
    " + stat_bin_2d(bins=40)\n",
    " + geom_smooth(method=\"lm\",color='red')\n",
    " + coord_equal()\n",
    " + theme_bw(20)\n",
    " + guides(color='F')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-private",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Using this kind of plot allows us to measure how many points there are in each bin and thus we are now going towards a quantitative plot. The colorbar on the side helps us to interpret the colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-drive",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reduce even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-relaxation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T06:55:06.547556Z",
     "start_time": "2021-04-22T06:55:05.496203Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(ggplot(df,aes(x='x',y='y'))\n",
    "  + geom_density_2d(aes(x='x', y='y', color='..level..'))\n",
    "  + geom_smooth(method=\"lm\")\n",
    "  + coord_equal() \n",
    "  + labs(color=\"Type\")\n",
    "  + theme_bw(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-heavy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T10:27:31.737385Z",
     "start_time": "2021-04-17T10:27:31.702009Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Common visualization packages for python\n",
    "\n",
    "- Matplotlib [Matplotlib 3.0 Cookbook](https://www.packtpub.com/big-data-and-business-intelligence/matplotlib-30-cookbook) or [ETHZ lib](https://learning.oreilly.com/library/view/matplotlib-30-cookbook/9781789135718), [code examples](https://github.com/PacktPublishing/Matplotlib-3.0-Cookbook)\n",
    "- Plotly\n",
    "- Seaborn\n",
    "- ggplot [R using the ggplot2 library](https://doi.org/10.1007/978-3-319-24277-4), which is ported to [python](https://www.datascienceworkshops.com/blog/plotnine-grammar-of-graphics-for-python).\n",
    "\n",
    "A short summary of these packages can be found [here](https://mode.com/blog/python-data-visualization-libraries/#:~:text=matplotlib%20is%20the%20O.G.%20of,language%20developed%20in%20the%201980s.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-approach",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "## Uncertainties\n",
    "\n",
    "## Statistics\n",
    "- I am not a statistician and is not a statistics course\n",
    "- If you have questions or concerns\n",
    " - Both ETHZ and Uni Zurich offer [__free__ consultation](https://math.ethz.ch/sfs/consulting/consulting-service.html) with real statisticians\n",
    " - They are rarely bearers of good news - you allways need more data... \n",
    " \n",
    "- Simulations (even simple ones) are very helpful \n",
    "- Try and understand the tests you are performing\n",
    "\n",
    "\n",
    "## Visualization\n",
    "- Visualization is the crowning piece of your investigation - make it count!\n",
    "- Many toolboxes can be used, choose the one that fits your needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54a361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "April 14, 2022 - ETH 227-0966-00L: Quantitative Big Imaging/Statistics and reproducibility",
   "header": "<table width='100%' style='margin: 0px;'><tr><td align='left'><img src='../../common/figures/eth_logo_kurz_pos.svg' style='height:30px;'></td><td align='right'><img src='../../common/figures/PSI-Logo.svg' style='height:50px;'></td></tr></table>",
   "scroll": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
